  

# Automation as a Means of Surveillance ㅤㅤㅤㅤ

### Central Theme

Ever-growing demands for efficiency have driven the automation of labor throughout history, whether through the division of tasks into menial units or through the actual supplanting of humans by machines. Either case makes clear that to imagine that labor can be automated is to imagine laborers as at least somewhat mechanical. As Marx notes in “The Factory,” this characterization is inherently dehumanizing and reductive: only the mechanical parts of laborers are useful, and their humanity is considered a mere inconvenience. In fact, it’s most expedient to describe laborers as black boxes, such that they can be quantified only by their explicit interactions with the system. 
	
Of course, even those most infatuated with the dreams of automation recognize that people are not truly black boxes. Nevertheless, the ‘master capitalists’ – those in charge of the automaton – imagine that some parts of human behavior can be treated as such; by giving people certain inputs (reward, punishment), they can expect certain outputs. Thus, in an effort to ‘nudge’ people toward desired, more mechanical behaviors, the master capitalist imposes practices of surveillance upon their subjects. Conveniently, the rationalized, automated workplace lends itself easily to these practices. To describe a laborer as a black box is to render their work (and hence their entire value) easily measurable and therefore easily surveilled. 
	
Hence, it is in the master capitalist’s best interest to trivialize the work done by any individual laborer. In The Anatomy of Work, Friedmann delivers a 20th-century account of this phenomenon: when the master divides the work of production into menial tasks that are easily imagined to be ‘mechanical,’ they (the master) are able to think less of and about the people who complete those tasks. That is, the more mechanical the work, the more efficient surveilling it is.

Running parallel to Friedmann’s work was the advent of the digital computer, which has come to optimize surveillance in every respect. Originating as a wartime technology, the computer was initially little more than a glorified calculator. Yet, even in its earliest iterations, it stirred the imaginations of people like Norbert Wiener. In The Human Use of Human Beings, Wiener ideates the computing machine as a ‘sense organ,’ collecting data from the environment and serving it in the form of ‘intelligence’ to managers. Throughout the Cold War, the ways in which the digital computer evolved – both in the American imagination and in reality – were influenced by Wiener’s cybernetic worldview. The computer became a device of surveillance and control, as symbolized by the colossal Semi-Automatic Ground Environment (SAGE) project of the late 20th century. As Edwards argues in The Closed World, SAGE “set the key pattern…for global oversight and control” (103).

The 21st-century state of surveillance is therefore determined largely by digital technologies. The development of the digital computer from something so unwieldy as the ENIAC to our handheld smartphones has revolutionized our lives, sometimes in sinister ways. As tools of surveillance, our digital devices ask that we sign away our privacy and, as Zuboff warns in Big Other, our agency. The computerized workplace is one in which the laborer is constantly watched; the Amazon Privacy Policy for Vehicle Camera Technology paints precisely this picture. 
	
Alarmingly, the computer is no longer strictly a workplace presence. To exist in today’s America is to be married to some digital device; this fact has given rise to the paradigm of surveillance capitalism. The paradigm, introduced by Zuboff and evidenced in Google’s 2014 acquisition of Nest Labs, suggests that the “Big Brother”-esque practices of automated labor have engulfed society as a whole. Surveillance capitalists propose that the more pervasive their surveillance becomes, the greater control they have over their ‘users.’ Personal data, as a token of surveillance, therefore becomes a form of currency; therein lies the novelty of big technology companies’ business models. The value they extract from their users isn’t in the form of labor – instead, they sustain themselves on identities, collected and constructed using the ultimate tool of surveillance.


### Das Kapital - The Factory

In Marx's seminal work Das Kapital, he critiques capitalism from his novel perspective of historical materialism, which places a society's economic structure (that is to say, how the population's relationships to the means of production are divided and structured) at the center of its history and culture. One of the main claims he develops is that since the capitalist mode of production incentivizes one to maximize their wealth, there exists an unavoidable class struggle between those who own the means the production and those who do not.

In the section entitled "The Factory", Marx provides a contemporary (for him) example of the class struggle being exacerbated by technological advancement. This comes in the form of late industrial revolution factories. Given how technology and production are closely intertwined, it's no surprise that Marx pays close attention to how technology (in this case, manufacturing equipment) meditates the relationship between workers and capital. One of the first claims he lays out is that as machinery is introduced, the workers who previously made the commodities themselves are reduced to operators of specific complex tools with no understanding of their inner workings. This overspecialization and expendability erodes the leverage the laborers have over those that own the factory, since both the transferrability of their skills and the cost of training a new employee are vastly reduced. Society's percention about the intellectual side of labor is changed as well, since the knowledge of production is encapsulated within the design of the machines, not the brains of the operators. 

Building off of this theme of technology mediating the relationship between workers and capitalists, Marx poses that the absolute power of the factory owner leads to rigid, mechanical treatment of the employees. The mechanization of the labor itself leads to the mechanization of the laborers, and the machines and employees end up being monitored as if they were equals.

One might argue that based on the characteristics of the technology, the advent of automation would make work more pleasant. This follows from the idea that technological advancement is a phenomenon independent of humans, and that it's simply up to us to adapt. The term for this line of reasoning is loosely referred to as technological determinism, and in 'Karl Marx and the Three Faces of Technological Determinism',  Bruce Bimber aims to concretely situate whether Marx's analyses agree with this model, and finds that the core of historical materialism rejects technological determinism.

 While Marxian analysis explains how and why capitalists subjugate their workers through the use of technology, Marx contextualizes this from the perspective of basic human needs. In his analysis, "history is the development of the labor process into a social process" (Bimber, 348), and technology is just wielded as a tool under the current social conditions. But given that the drivers of technological development are the holders of capital, is it not inevitable that technology reflects and reinforces the values of the capitalists?


### Anatomy Of Work 

Georges Friedmann addresses various questions raised regarding human labor and development, particularly in regards to the introduction of automation into the workplace. In the first few chapters, Friedmann comments on many trends he is seeing unfold within factories in the 1960s in order to form a bigger argument that the introduction of electronic devices and other automated devices will have a profound impact on workers’ relationships with and interests in their jobs. One of the salient trends he analyzed in order to form this broader argument was a Parisian biscuit factory that implemented a job rotation schedule where the tasks of each group would be changed weekly. He found that this resulted in increased job satisfaction and an overall net positive relationship between the worker and the fruits of their labor, regardless of the tasks being menial or not. He calls this subdividing and simplifying the work in order to give more business to the machine; where the human becomes a machine himself because of the radical simplification of his work. The second recent production trend Friedmann identifies is this specialization of work. This can be seen in American public utility corporations where the process of gathering power grid data is extremely time-consuming and requires a multitude of groups that are each highly trained in one specific task. These two trends – amongst others that Friedmann predicted as early as 1961 – merge to form the backbone of his salient argument which supports the central thesis of our website. Friedmann uses the idea of a technician’s utopia to elucidate another argument; one where he asserts that the division of labor is perhaps a necessary evil that is the result of labor having been simplified to its extreme limit for machines to take the place of the man. Our website argues that automated technologies give system designers more means of control; and this will consequently revolutionize how people behave at work. This 20th century source affirms the fact that surveillance and capitalism are inextricably linked because surveillance is an important vehicle for capitalism as it ensures labor efficiency. In the 1960s, this hyper-focused surveillance was on the workers rather than consumers as it is today. Additionally, one of the main goals of the website is to identify and analyze historical patterns in labor surveillance. Friedmann’s text illuminated many of these patterns such as the decomposition of the labor force and the substitution of electronic for bureaucratic control. These salient shifts establish a more anomic and alienated workplace over time.


### The Human Use of Human Beings

Norbert Wiener’s The Human Use of Human Beings (1950) explores the rise of cybernetics, and bridges a historical perspective on the subject with contemporary concerns about its impact on society. In particular, the chapter “The First and Second Industrial Revolution” explains the rise of a second wave of industrial revolution. Unlike the first industrial revolution, which only displaced physical human labor, the second displaced lower-level or lower-judgment repetitive tasks with machines that can be “taped” (i.e. programmed). Wiener fears that this will result in massive unemployment that will make “even the depression of the thirties… seem [like] a pleasant joke” (189).

Wiener effectively bridges the first industrial revolution, explored in the primary sources above, with the further rise of automation through technology in the 20th century. In particular, Wiener sets the stage to allow for computers to become information-processing devices.

He notes that the computing machine has “sense organs, such as photo-electric cells” that can collect, or “sense,” data from their environment (Wiener, 183).These machines have control systems that can “carry out feedback operations” (Wiener, 184). These features, according to the author, make it possible to program machines to displace lower-judgment labor in a vast array of fields. Through this, we see that Wiener sees computing machines not as data processors, but as being more generalized devices, a precursor to ideas compatible with Haigh. Haigh explains how many in the 1960’s sought computers to be a management information system (MIS) able to “replace accountants as the primary agents of managerial control” (Haigh, 15). Building on the automation of administrative processes in the 1950’s, computers could be tightly integrated with their environment to process “information” and serve “intelligence” to people like higher-level management (Haigh, 16). Wiener’s work is a precursor to this being a possibility; such a MIS no doubt requires some type of “sense organs” to collect data from their environment, and the notion of replacing accountants in management with machines is compatible with the second industrial revolution replacing a broad range of lower-judgment or repetitive tasks. Beyond this, Haigh indicates that the MIS ended up being infeasible in the 1960s, but that this notion led to an “association of information with the computer” (Haigh, 15). Under this lens, Wiener’s predictions for generalized computing machines collecting information about their environment and processing it (through feedback mechanisms) is arguably a precursor to the types of surveillance that have since evolved in the form of “big data” in the present day, as seen in Zuboff’s explanation of surveillance capitalism, which requires immense automated data collection from the outside world. 

Therefore, Wiener presented a variety of ideas in this chapter, including how computing machines have the technology to “sense” their environment and how these machines could displace workers via a second industrial revolution. However, because this latter displacement of workers was arguably not as extensive as Wiener feared (e.g. we have not had another depression as a result of the displaced labor), perhaps Wiener’s ideas are best seen in terms of an evolution towards this association between information and computers, and as a precursor to computers as a method of modern-day data collection and surveillance.

### Amazon's Labor Surveillance
Modern data collection technologies exist to extract capital from both sides of the capitalist coin, from the consumer to the human resource. Zuboff states that “the titanic power struggles of the twentieth century were between industrial capital and labor, the twenty-first century finds surveillance capital pitted against the entirety of our societies, right down to each individual member” (11). The power and extent of data collection practices have pushed their use beyond the sphere of labor management, but they have still maintained an even stronger presence within it. This Privacy Policy, created to establish Amazon’s right to monitor any drivers of their vehicles, is a prime example of this presence.

The power of the technology is represented in the laundry list of data items that the company admits to collecting. A camera gives the company full access to all the drivers’ actions while on the job. The company also flexes that they have data to describe all other details of the job performance “such as miles driven, speed, acceleration, braking, turns, following distance.” With even more items listed, the document allows for no doubt that the company sees everything that the driver does.

Amazon then holds this power over the driver, explaining that the data is “available to your DSP [employer]” and used “to assess your ongoing eligibility to perform services under your DSP’s contract with Amazon” or “to manage Amazon’s contractual relationship with your DSP.” In this context, DSP stands for Delivery Service Partner, and is the company through which Amazon is hiring the driver. Essentially, Amazon is expressing that the data collected is sent to their employers and, through a mess of contracts and red tape, can be used to determine the future of their employment.

In this way, the company takes their surveillance technology and asserts it as a means of control over the work force. By threatening unemployment, they strike at the source of most people’s welfare, equating conformity with company policy with overall well-being. This is not an uncommon labor practice in 21st century America. You might even be thinking “well, of course, I’m always a few wrong steps away from being fired.” But what are the consequences of this in the context of data collection technologies that allow every facet of our behavior to be monitored. Are we really expected to act like the mindless drones that our company service agreements paint us as? With surveillance technologies allowing companies to track every step we take, that exact expectation is thrust upon us, lest we lose our source of income.

Amazon’s labor surveillance system has also clearly developed alongside the techniques they use to mine consumer data. Zuboff points out that “Amazon acquires comprehensive data on people’s actual living habits, which it learns how to fabricate into behavioral predictions for sale in behavioral futures markets for real-world services.” The company’s marriage to these principles is maintained within the context of their labor management. The agreement admits that the data collected can be used “to troubleshoot and improve Amazon’s services” and that the camera may be accessed “Immediately when information useful to improve maps and routing is detected.” In these uses, the company exposes their intention to use drivers’ labor to train their data infrastructure. This is particularly significant in the context of Amazon’s drive for automation. As Kaoosji addresses, “Amazon has explicitly stated that its goal is to automate its warehouse and delivery driver workforces.” (198).

So not only is the data collection being leveraged as a method of controlling drivers’ behavior, but so too might it be used to train the automated system that Amazon hopes to implement to replace the drivers. This data collection happens at the expense of the drivers, who must experience the constant stress of being monitored alongside an already taxing occupation, and whose compensation does not factor in the added value that Amazon is able to extract from the collected data.


### Google's 2014 Acquisition of Nest Labs

In this Washington Post article, Fung reports on Google’s 2014 acquisition of Nest Labs and the subsequent discourse concerning Google’s handling of user data. In 2014, Nest was producing ‘learning thermostats’ - thermostats that learned and adjusted to their users’ daily routines - and had recently expanded into connected smoke alarms. Its acquisition, which cost Google $3.2 billion, marked Google’s first move into the market of ‘smart homes.’ 
	
The move sparked discussion about Nest’s user data, and about Nest and Google’s privacy policies in general. With access to data about thermostat use, Google could learn the details of a user’s day-to-day. Combined with Google’s already extensive array of behavioral data, the company could make increasingly precise and privacy-invasive determinations about its users. While Nest’s privacy policy at the time promised that its user data would only be used for its own products, David Jacobs, a lawyer at the Electronic Privacy Information Center, warned that this promise could be nullified at any time by a revision to the policy. He also noted that, as had been the case throughout the company’s history, Google’s attitude toward concerns surrounding any such revisions would likely be “you [the user] accept the changes or you use something else.”
	
In ‘Big Other,’ Zuboff echoes this sentiment: above all else, Google “takes what it wants” and asks permission only when faced with resistance (78). This pattern was established in Google Street View, when Google deployed Street View cars “equipped with scanners to scrape data from private Wi-Fi networks.” It was therefore entirely unsurprising that some were wary of Google’s looming eye creeping into the sphere of their homes. Home monitoring is inherently somewhat invasive, but the folding of Nest into Google was uniquely problematic because of Google’s ambition to build “a system of almost universal surveillance” (Vaidhyanathan, 84). As Bronfman notes in ‘Weathering the Nest,’ when all information is unified in a single platform, people are less able to distinguish between the information that they would like to share and that which they would not. They pay less attention to the differing sensitivities of their personal data when all of the entities that collect their data appear to be ‘seamless,’ as Google’s smart home appliances strive to be. To compound this problem further, even pieces of information that seem innocuous may have “economic or strategic value” when combined with other data to “replicate an identity of an individual with increasing ease and accuracy” (Bronfman, 195). 
	
While the Google-Nest merger was initially far less successful than hoped for, it signified Google’s entrance into the market of connected appliances. Today, Google Nest encompasses all of Google’s smart home devices, as was originally intended (Statt & Bohn). Within the context of Google’s historic disregard for their user’s data privacy rights, it’s difficult to see the merger as anything other than an expansion of the company’s sphere of surveillance. The fact that Nest customers were forced to either accept the implications of the merge or ‘use something else’ highlights the power differential between today’s technology companies and their users. Surveillance capitalists consistently fail to recognize or acknowledge this imbalance, often justifying their entitlement to their users’ identities by arguing that users choose to use their products, and can at any time choose not to. This is true: users can opt-out of Google’s services as they choose; but when making informed decisions on whether to do so means wading through illegibly dense privacy policies that can change at any time, these choices mean precious little (Vaidhyanathan, 84). The Google-Nest merger hence illustrates the total lack of reciprocity between surveillance capitalists and their users.


### Bibliography

Amazon. “Amazon Privacy Policy for Vehicle Camera Technology,” in Vincent, James. 2021. “Amazon Delivery Drivers Have to Consent to AI Surveillance in Their Vans or Lose Their Jobs.” The Verge. March 24, 2021. Available at: https://www.theverge.com/2021/3/24/22347945/amazon-delivery-drivers-ai-surveillance-cameras-vans-consent-form.. 

Bimber, Bruce. “Karl Marx and the Three Faces of Technological Determinism.” _Social Studies of Science_ 20, no. 2 (1990): 333–51. http://www.jstor.org/stable/285094.

Bronfman, Jill, Weathering the Nest: Privacy Implications of Home Monitoring for the Aging American Population (September 2, 2015). Duke Law & Technology Review, Forthcoming, Available at SSRN: https://ssrn.com/abstract=2654984.

Edwards, Paul. “Sage,” in The Closed World: Computers and the Politics of Discourse in Cold War America, 75-111. Cambridge: The MIT Press, 1997.

Friedmann, G., 1961. Anatomy of work: labor, leisure, and the implications of automation : Friedmann, Georges. Internet Archive. Available at: https://archive.org/details/anatomyofworklab00frie/page/n21/mode/2up .
 
Fung, Brian. 2014. Google just Bought Nest for $3.2 Billion. What Happens to Nest's User Data?: Washington: WP Company LLC d/b/a The Washington Post. http://ccl.idm.oclc.org/login?url=https://www.proquest.com/blogs-podcasts-websites/google-just-bought-nest-3-2-billion-what-happens/docview/1491792127/se-2?accountid=10141

Haigh, Thomas. “Inventing Information Systems: The Systems Men and the Computer, 1950-1968.” _The Business History Review_ 75, no. 1 (2001): 15–61. https://doi.org/10.2307/3116556.

Kalischko, T. and Riedl, R., 2021. Electronic Performance Monitoring in the Digital Workplace: Conceptualization, Review of Effects and Moderators, and Future Research Opportunities. Frontiers in Psychology, 12.
 
Kaoosji, Sheheryar. “Worker and Community Organizing to Challenge Amazon’s Algorithmic Threat.” In _The Cost of Free Shipping: Amazon in the Global Economy_, edited by Jake Alimahomed-Wilson and Ellen Reese, 194–206. Pluto Press, 2020. https://doi.org/10.2307/j.ctv16zjhcj.19.

Karl Marx, “The Factory” in Capital, Vol. 1, Ch. 15, Section 4.

Sperber, J., 2014. Yelp and Labor Discipline. New Labor Forum, 23(2), pp.68-74.

Statt, Nick, and Dieter Bohn. “Google Nest: Why Google Finally Embraced Nest as Its Smart Home Brand.” The Verge. The Verge, May 7, 2019. https://www.theverge.com/2019/5/7/18530609/google-nest-smart-home-brand-merging-hub-max-rebrand-io-2019. 

Vaidhyanathan, Siva. (2011). The Googilization of Everything, Berkeley, CA: University of California Press.

Zuboff, Shoshana. “Big Other: Surveillance Capitalism and the Prospects of an Information Civilization.” Journal of Information Technology 30, no. 1 (March 2015): 75–89. https://doi.org/10.1057/jit.2015.5. 

Zuboff, Shoshana. “Surveillance Capitalism and the Challenge of Collective Action.” New Labor Forum 28, no. 1 (January 2019): 10–29. https://doi.org/10.1177/1095796018819461.
